{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict 2 meter temperature with sea surface temperature using linear regression\n",
    "This notebook serves as an example of a basic workflow of data driven forecasting using machine learning with `s2spy` & `lilio` packages. <br>\n",
    "We will predict temperature in US at seasonal time scales using ERA5 dataset with linear regression (Ridge). <br>\n",
    "\n",
    "<img src=\"../assets/concept_test_case.png\" alt=\"usecase\" width=\"500\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This recipe includes the following steps:\n",
    "- Define a calendar (`lilio`)\n",
    "- Download/load input data (test data, accessible via `era5cli`)\n",
    "- Map the calendar to the data (`lilio`)\n",
    "- Train-test split (70%/30%)\n",
    "- Preprocessing based on the training set (`s2spy`)\n",
    "- Resample data to the calendar (`lilio`)\n",
    "- Dimensionality reduction and model training, with cross-validation (`lilio` & `scikit-learn`)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow is illustrated below:\n",
    "\n",
    "<img src=\"../assets/regression.PNG\" alt=\"Ridge\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lilio\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from s2spy import preprocess\n",
    "from s2spy import RGDR\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a calendar with `lilio` to specify time range for targets and precursors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom calendar based on the time of interest\n",
    "calendar = lilio.Calendar(anchor=\"07-01\", allow_overlap=True)\n",
    "# add target periods\n",
    "calendar.add_intervals(\"target\", length=\"30d\", gap=\"1M\")\n",
    "# add precursor periods\n",
    "periods_of_interest = 4\n",
    "calendar.add_intervals(\"precursor\", \"1M\", n=periods_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check calendar\n",
    "calendar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load test data SST and (clustered) T2M\n",
    "We use 63 years (1959-2021) of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "precursor_field = xr.open_dataset('../data/sst_daily_1959-2021_5deg_Pacific_175_240E_25_50N.nc')\n",
    "target_field = xr.open_dataset('../data/t2m_daily_1959-2021_2deg_clustered_226_300E_30_70N.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Klevin to Celcius\n",
    "precursor_field[\"sst\"] = precursor_field[\"sst\"] - 273.15\n",
    "target_field[\"t2m\"] = target_field[\"t2m\"] - 273.15"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map the calendar to the data\n",
    "After mapping the calendar to the field, we can visualize our calendar by calling the `visualize` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map calendar to data\n",
    "calendar.map_to_data(precursor_field)\n",
    "calendar.visualize(show_length=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we can get a list of all intervals by running the following line. There, you will find the intervals `-1` and `1`, which corresponds to the creation of a precursor interval (negative integer(s)) and a target interval (positive integer(s)), respectively. <br>\n",
    "\n",
    "For more information about the definition of intervals, and how `lilio` works, please check the [README](https://github.com/AI4S2S/lilio) of `lilio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 5 anchor years in the calendar\n",
    "calendar.show()[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split based on the anchor years (70%/30% split)\n",
    "This can be refered to as the \"outer cross-validation layer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 70% of instance as training\n",
    "years = sorted(calendar.get_intervals().index)\n",
    "train_samples = round(len(years) * 0.7)\n",
    "start_year = years[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit preprocessor with training samples and preprocess data\n",
    "In this step, we remove trend and take anomalies for the precursor field. Note that here we use raw daily data for detrending and taking anomalies. <br>\n",
    "\n",
    "In general, there are many \"flavors\" of preprocessing, like when to perform this operation, and in which order do we want to preprocess the data. To improve the transparency and reproducibility of our work, we think it is necessary to standardize these steps. To stick to the best practices, we suggest to preprocess your data in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create preprocessor\n",
    "preprocessor = preprocess.Preprocessor(\n",
    "    rolling_window_size=25,\n",
    "    detrend=\"linear\",\n",
    "    subtract_climatology=True,\n",
    ")\n",
    "\n",
    "# fit preprocessor with training data\n",
    "preprocessor.fit(\n",
    "    precursor_field.sel(\n",
    "        time=slice(str(start_year), str(start_year + train_samples - 1))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the whole precursor field\n",
    "precursor_field_prep = preprocessor.transform(precursor_field)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample data to the calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precursor_field_resample = lilio.resample(calendar, precursor_field_prep)\n",
    "target_field_resample = lilio.resample(calendar, target_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variables and intervals\n",
    "precursor_field_sel = precursor_field_resample['sst']\n",
    "target_series_sel = target_field_resample['t2m'].sel(cluster=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split -> dimensionality reduction & model fitting\n",
    "Train-test split based on the previous split, which can be refered to as \"inner cross-validation layer\" (outer cv loop -> inner cv loop). <br>\n",
    "For each split, we will perform dimensionality reduction and fit the model.\n",
    "\n",
    "For simplicity, in this example we only perform dimensionality reduction with RGDR with only one target interval and one lag. But in practice you can have multiple target intervals and multiple lags. <br>\n",
    "For more information, here is a nice example about multiple target intervals in the [tutorial notebook](https://github.com/AI4S2S/s2spy/blob/main/docs/notebooks/tutorial_RGDR.ipynb) of RGDR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress numpy warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# cross-validation with Kfold\n",
    "k_fold_splits = 5\n",
    "kfold = KFold(n_splits=k_fold_splits)\n",
    "cv = lilio.traintest.TrainTestSplit(kfold)\n",
    "\n",
    "# create lists for saving models and predictions\n",
    "models = []\n",
    "predictions = []\n",
    "rmse_train = []\n",
    "rmse_test = []\n",
    "train_test_splits = []\n",
    "\n",
    "# prepare operator for dimensionality reduction\n",
    "target_intervals = 1\n",
    "lags = list(np.arange(1, periods_of_interest + 1))\n",
    "\n",
    "# cross validation based dimensionality reduction and model training\n",
    "for split, (x_train, x_test, y_train, y_test) in enumerate(cv.split(precursor_field_sel, y=target_series_sel)):\n",
    "    clusters_train_lags = []\n",
    "    clusters_test_lags = []\n",
    "    for lag in lags:\n",
    "        # log train/test splits with anchor years\n",
    "        train_test_splits.append({\n",
    "            \"train\": x_train.anchor_year.values,\n",
    "            \"test\": x_test.anchor_year.values,\n",
    "        })\n",
    "        # RGDR\n",
    "        rgdr = RGDR(\n",
    "            target_intervals=target_intervals,\n",
    "            lag=lag,\n",
    "            eps_km=600,\n",
    "            alpha=0.05,\n",
    "            min_area_km2=0\n",
    "            )\n",
    "        # fit dimensionality reduction operator RGDR and transform\n",
    "        clusters_train_lag_xr = rgdr.fit_transform(x_train, y_train)\n",
    "        clusters_test_lag_xr = rgdr.transform(x_test)\n",
    "        # convert to numpy array, reshape and append\n",
    "        clusters_train_lag = clusters_train_lag_xr.to_numpy()\n",
    "        clusters_train_lag = clusters_train_lag.reshape(len(clusters_train_lag_xr.anchor_year),-1)\n",
    "        clusters_train_lags.append(clusters_train_lag)\n",
    "        clusters_test_lag = clusters_test_lag_xr.to_numpy()\n",
    "        clusters_test_lag = clusters_test_lag.reshape(len(clusters_test_lag_xr.anchor_year),-1)\n",
    "        clusters_test_lags.append(clusters_test_lag)\n",
    "    # concatenate lags\n",
    "    clusters_train = np.concatenate(clusters_train_lags, axis=1)\n",
    "    clusters_test = np.concatenate(clusters_test_lags, axis=1)\n",
    "    # train model\n",
    "    ridge = RidgeCV(alphas=[0.1, 10, 25, 50])\n",
    "    model = ridge.fit(clusters_train, y_train.sel(i_interval=1))\n",
    "    # save model\n",
    "    models.append(model)\n",
    "    # predict and save results\n",
    "    prediction = model.predict(clusters_test)\n",
    "    predictions.append(prediction)\n",
    "    # calculate and save rmse\n",
    "    rmse_train.append(mean_squared_error(y_train.sel(i_interval=1),\n",
    "                                            model.predict(clusters_train)))\n",
    "    rmse_test.append(mean_squared_error(y_test.sel(i_interval=1),\n",
    "                                        prediction))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "# y_train\n",
    "plt.plot(y_train.anchor_year, y_train.sel(i_interval=1), \"b\", label = \"y_train\")\n",
    "plt.plot(y_train.anchor_year, model.predict(clusters_train), \"b--\", label = \"training\")\n",
    "# y_test\n",
    "plt.plot(y_test.anchor_year, y_test.sel(i_interval=1), \"r\", label = \"y_test\")\n",
    "plt.plot(y_test.anchor_year, prediction, \"r--\", label = \"prediction\")\n",
    "plt.xlabel(\"years\")\n",
    "plt.ylabel(\"deg C\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the RMSE for both training and testing for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "xrange = np.arange(1, k_fold_splits + 1)\n",
    "plt.plot(xrange, rmse_train, \"b--\", label = \"train loss\")\n",
    "plt.plot(xrange, rmse_test, \"r\", label = \"test loss\")\n",
    "ax = fig.gca()\n",
    "ax.set_xticks(xrange)\n",
    "plt.xlabel(\"Fold\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
